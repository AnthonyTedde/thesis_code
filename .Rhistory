)
n <- 100
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
n <- 50
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
n <- 20
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
n <- 30
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
n <- 40
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
n <- 23
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
X <- rowSums(Y)
X
n <- 3
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
n <- 4
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y
Y/2
apply(Y, 2)
apply(Y, 2, Y/2)
apply(Y, 2, function(x) x/2)
apply(Y, 2, function(x) x/1:4)
apply(Y, 1, function(x) x/1:4)
t(apply(Y, 1, function(x) x/1:4))
t(apply(Y, 1, function(x) x/(1:4)))
t(apply(Y, 1, function(x) x/2^(1:4)))
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^1:n))
Y
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
Y
n
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
Y
X <- rowSums(Y)
X
n <- 25
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
rm(list = ls())
gc(verbose = T)
n <- 25
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
n <- 20
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
X <- rowSums(Y)
X[1]
X[2]
X[3]
X[4]
X[5]
X[length(X)]
X <- order(X)
head(X)
?order
X <- rowSums(Y)
X <- sort(X)
X
head(X)
tail(X)
X <- sort(rowSums(Y), decreasing = T)
plot(X)
#################################################################
# Example 1.2.5: Another random variable uniformly distributed.
################################################################
# W random variables included various value from 0 to one.
# All UNIFORMALY distributed.
W <- seq(from = 0,
to = 1,
by = .0001)
#
# Define the probability measure p & q
p <- 1/2
q <- 1 - p
# number of exeriments: expe
expe <- 100000
# Sample size:
n <- 100
##
# Construction of the theoretical distribution of X
#
# Not consider the infinite sample space but instead a rather large one
#
#   * [n]: It gives the number of columns.
#   * [2^n]: Gives the number of rows.
##
n <- 20
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
X <- sort(rowSums(Y), decreasing = T)
length(X)
distrib_X <- data.frame('X' = X, 'P' = 1/length(X))
head(distrib_X)
sum(rowSums(distrib_X))
sum(distrib_X[1] * distrib_X[2])
sum(distrib_X[2])
sum(rowProds(distrib_X))
install.packages("matrixStats")
library(matrixStats)
sum(rowProds(distrib_X))
sum(rowProds(as.matrix(distrib_X)))
probX <- 1/length(X)
sum(X * probX)
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(0, 1, by = 1/length(X)))
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(1/length(X), 1, by = 1/length(X)))
head(distrib_X)
tail(distrib_X)
library(ggplot2)
ggplot(distrib_X, aes(X, F)) +
geom_line()
a <- 0.125
X <- rowSums(Y)
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(2/length(X), 1, by = 1/length(X)))
X <- rowSums(Y)
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(2/length(X), 1, by = 1/length(X)))
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(1/length(X), 1, by = 1/length(X)))
ggplot(distrib_X, aes(X, F)) +
geom_line()
ggplot(distrib_X, aes(X, F)) +
geom_point()
#################################################################
# Example 1.2.5: Another random variable uniformly distributed.
################################################################
library(ggplot2)
# W random variables included various value from 0 to one.
# All UNIFORMALY distributed.
W <- seq(from = 0,
to = 1,
by = .0001)
#
# Define the probability measure p & q
p <- 1/2
q <- 1 - p
# number of exeriments: expe
expe <- 100000
# Sample size:
n <- 100
##
# Construction of the theoretical distribution of X
#
# Not consider the infinite sample space but instead a rather large one
#
#   * [n]: It gives the number of columns.
#   * [2^n]: Gives the number of rows.
##
n <- 20
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
X <- rowSums(Y)
ordered_X <- sort(rowSums(Y), decreasing = T)
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(1/length(X), 1, by = 1/length(X)))
ggplot(distrib_X, aes(X, F)) +
geom_point()
# Find the expected value:
prob_X <- 1/length(X)
sum(X * prob_X)
##
# Next: Convergence of Integrals.
##
#
# Y should be constructed according to some random experiment.
Y = list()
for(i in 1:expe){
Y[[i]] <- rbinom(n = n,
size = 1,
prob = p)
}
# According to Y, construction of X:
# X should be a random variable construct upon a vector
# Transformation of Y
YPrime <- Y
for(i in 1:expe)
for(j in 1:n)
YPrime[[i]][j] <- Y[[i]][j] / 2^j
X <- vector()
for(i in 1:expe)
X[i] <- sum(YPrime[[i]])
# Probability that the value of X fall between 4/3000 and 5/3000:
ProbX <- 1 / 2 ^ n
####################################################
#  Check of the theory
####################################################
# Probability that X is in the interval:
# [0, 3e29/2^n]:
probI <- (3e29 - 0)/2^n
# Check:
length(X[X < 3e29/2^n]) / length(X)
# Probability that X is in the interval:
# [3e28/2^n, 3e29/2^n]:
probI <- (3e29 - 3e28)/2^n
# Check:
length(X[X > 3e28/2^n & X < 3e29/2^n]) / length(X)
#################################################################
# Example 1.2.5: Another random variable uniformly distributed.
################################################################
library(ggplot2)
# W random variables included various value from 0 to one.
# All UNIFORMALY distributed.
W <- seq(from = 0,
to = 1,
by = .0001)
#
# Define the probability measure p & q
p <- 1/2
q <- 1 - p
# number of exeriments: expe
expe <- 100000
# Sample size:
n <- 100
##
# Construction of the theoretical distribution of X
#
# Not consider the infinite sample space but instead a rather large one
#
#   * [n]: It gives the number of columns.
#   * [2^n]: Gives the number of rows.
##
n <- 20
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
X <- sort(rowSums(Y), decreasing = T)
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(1/length(X), 1, by = 1/length(X)))
ggplot(distrib_X, aes(X, F)) +
geom_point()
# Find the expected value:
prob_X <- 1/length(X)
sum(X * prob_X)
##
# Next: Convergence of Integrals.
##
#
# Y should be constructed according to some random experiment.
Y = list()
for(i in 1:expe){
Y[[i]] <- rbinom(n = n,
size = 1,
prob = p)
}
# According to Y, construction of X:
# X should be a random variable construct upon a vector
# Transformation of Y
YPrime <- Y
for(i in 1:expe)
for(j in 1:n)
YPrime[[i]][j] <- Y[[i]][j] / 2^j
X <- vector()
for(i in 1:expe)
X[i] <- sum(YPrime[[i]])
# Probability that the value of X fall between 4/3000 and 5/3000:
ProbX <- 1 / 2 ^ n
####################################################
#  Check of the theory
####################################################
# Probability that X is in the interval:
# [0, 3e29/2^n]:
probI <- (3e29 - 0)/2^n
# Check:
length(X[X < 3e29/2^n]) / length(X)
# Probability that X is in the interval:
# [3e28/2^n, 3e29/2^n]:
probI <- (3e29 - 3e28)/2^n
# Check:
length(X[X > 3e28/2^n & X < 3e29/2^n]) / length(X)
library(ggplot2)
a <- 0
b <- 4
max_length <- (b-a) / 100
max_length
?seq
seq(a, b, by = max_length)
max(c(1, 2,3))
?max
optimize(x^2, lower = 0, upper = 0.4, maximum = T)
optimize(function(x) x^2, lower = 0, upper = 0.4, maximum = T)
0.4^2
0.2^2
0.3999^2
optimise(function(x) x^2, lower = 0, upper = 0.4, maximum = T)
x_square <- function(x) x^2
optimise(x_square, lower = partition_point[1],
upper = partition_point[2],
maximum = T)
partition_tmp <- 100
max_length <- (b-a) / partition_tmp
partition_point <- seq(a, b, by = max_length)
partition_point
x_square <- function(x) x^2
optimise(x_square, lower = partition_point[1],
upper = partition_point[2],
maximum = T)
optimise(x_square, lower = partition_point[1],
upper = partition_point[2],
maximum = T)$objective
1:length(partition_point)
for(i in 2:length(partition_point))
optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
i
for(i in 2:length(partition_point))
optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
a <- for(i in 2:length(partition_point))
optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
a
for(i in 2:length(partition_point))
a[i-1] <- optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
a
a*partition_point
length(a)
length(partition_point)
a*max_length
sum(a*max_length)
4^3
/3
64/3
sum(upper * max_length)
x_square <- function(x) x^2
for(i in 2:length(partition_point))
upper[i-1] <- optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
for(i in 2:length(partition_point))
lower[i-1] <- optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
upper <- lower <- vector()
for(i in 2:length(partition_point))
upper[i-1] <- optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
for(i in 2:length(partition_point))
lower[i-1] <- optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i],
maximum = T)$objective
sum(upper * max_length)
4^3
/3
64/3
sum(lower * max_length)
for(i in 2:length(partition_point))
lower[i-1] <- optimise(x_square, lower = partition_point[i-1],
upper = partition_point[i])$objective
sum(lower * max_length)
# By consequence the Upper Riemann integral is:
upper_riemann_sum <- sum(upper * max_length)
# And the lower:
lower_riemann_sum <- sum(lower * max_length)
c(1,0)
list(c(1,0))
k <- 20
Y <- expand.grid(
rep(list(c(1,0)), n)
)
Y[10,10]
Y[10,]
Y[, 10
]
Y[,1]
Y[,2]
Y[,3]
Y[,1:3]
Y <- t(apply(Y, MARGIN = 1,FUN = function(x) x/2^(1:n)))
X <- sort(rowSums(Y), decreasing = T)
head(X)
X[1]
X[length(X)]
Y[1:3, 1:3]
Y[1:10, 1:10]
period <- c(0, 1)
S0      <- 4
k       <- 5
u       <- 2
r       <- 1/4
p       <- 0.5
X0      <- 1.20
delta0  <- 0.5
stockPricePath_f = function(i, j){
ifelse(j >= i,
u ^(j - i) * d^(i - 1) * S0,
NA_integer_)
}
stockPricePath <- outer(period + 1,
period + 1,
stockPricePath_f)
stockPricePath_f = function(i, j){
ifelse(j >= i,
u ^(j - i) * d^(i - 1) * S0,
NA_integer_)
}
stockPricePath <- outer(period + 1,
period + 1,
stockPricePath_f)
d <- 1/u
stockPricePath <- outer(period + 1,
period + 1,
stockPricePath_f)
stockPricePath
k <- 3
Y <- expand.grid(
rep(list(c(1,0)), k)
)
Y
n <- 20
Y <- expand.grid(
rep(
list(c(1,0)),
n)
)
Y <- t(apply(Y, MARGIN = 1, FUN = function(x) x/2^(1:n)))
X <- sort(rowSums(Y), decreasing = T)
distrib_X <- data.frame('X' = X,
'P' = 1/length(X),
'F' = seq(1/length(X), 1, by = 1/length(X)))
ggplot(distrib_X, aes(X, F)) +
geom_point()
library(ggplot2)
ggplot(distrib_X, aes(X, F)) +
geom_point()
